<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Data Analysis and Machine Learning: Logistic Regression">

<title>Data Analysis and Machine Learning: Logistic Regression</title>

<!-- Bootstrap style: bootstrap -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}

/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Logistic Regression', 2, None, '___sec0'),
              ('Optimization and Deep learning', 2, None, '___sec1'),
              ('Basics', 2, None, '___sec2'),
              ('Linear classifier', 2, None, '___sec3'),
              ('Some selected properties', 2, None, '___sec4'),
              ('The logistic function', 2, None, '___sec5'),
              ('Two parameters', 2, None, '___sec6'),
              ('Maximum likelihood', 2, None, '___sec7'),
              ('The cost function rewritten', 2, None, '___sec8'),
              ('Minimizing the cross entropy', 2, None, '___sec9'),
              ('A more compact expression', 2, None, '___sec10'),
              ('Extending to more predictors', 2, None, '___sec11'),
              ('Including more classes', 2, None, '___sec12'),
              ('The Softmax function', 2, None, '___sec13'),
              ('A _scikit-learn_ example', 2, None, '___sec14'),
              ('A simple classification problem', 2, None, '___sec15'),
              ('The two-dimensional Ising model, Predicting phase transition '
               'of the two-dimensional Ising model',
               2,
               None,
               '___sec16'),
              ('Reading in the data', 2, None, '___sec17'),
              ('Logistic regression', 2, None, '___sec18'),
              ('Exploring the logistic regression', 2, None, '___sec19'),
              ('Accuracy of a classification model', 2, None, '___sec20'),
              ('Analyzing the results', 2, None, '___sec21'),
              ('Credit Card data set', 2, None, '___sec22'),
              ('The Pulsar classification case', 2, None, '___sec23')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="LogReg-bs.html">Data Analysis and Machine Learning: Logistic Regression</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._LogReg-bs001.html#___sec0" style="font-size: 80%;">Logistic Regression</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs002.html#___sec1" style="font-size: 80%;">Optimization and Deep learning</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs003.html#___sec2" style="font-size: 80%;">Basics</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs004.html#___sec3" style="font-size: 80%;">Linear classifier</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs005.html#___sec4" style="font-size: 80%;">Some selected properties</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs006.html#___sec5" style="font-size: 80%;">The logistic function</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs007.html#___sec6" style="font-size: 80%;">Two parameters</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs008.html#___sec7" style="font-size: 80%;">Maximum likelihood</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs009.html#___sec8" style="font-size: 80%;">The cost function rewritten</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs010.html#___sec9" style="font-size: 80%;">Minimizing the cross entropy</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs011.html#___sec10" style="font-size: 80%;">A more compact expression</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs012.html#___sec11" style="font-size: 80%;">Extending to more predictors</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs013.html#___sec12" style="font-size: 80%;">Including more classes</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs014.html#___sec13" style="font-size: 80%;">The Softmax function</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs015.html#___sec14" style="font-size: 80%;">A <b>scikit-learn</b> example</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs016.html#___sec15" style="font-size: 80%;">A simple classification problem</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs017.html#___sec16" style="font-size: 80%;">The two-dimensional Ising model, Predicting phase transition of the two-dimensional Ising model</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs018.html#___sec17" style="font-size: 80%;">Reading in the data</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs019.html#___sec18" style="font-size: 80%;">Logistic regression</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs020.html#___sec19" style="font-size: 80%;">Exploring the logistic regression</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs021.html#___sec20" style="font-size: 80%;">Accuracy of a classification model</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs022.html#___sec21" style="font-size: 80%;">Analyzing the results</a></li>
     <!-- navigation toc: --> <li><a href="#___sec22" style="font-size: 80%;">Credit Card data set</a></li>
     <!-- navigation toc: --> <li><a href="._LogReg-bs024.html#___sec23" style="font-size: 80%;">The Pulsar classification case</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0023"></a>
<!-- !split  -->

<h2 id="___sec22" class="anchor">Credit Card data set </h2>

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">pandas</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">pd</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">os</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>

<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.models</span> <span style="color: #008000; font-weight: bold">import</span> Sequential
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.layers</span> <span style="color: #008000; font-weight: bold">import</span> Dense
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.utils</span> <span style="color: #008000; font-weight: bold">import</span> to_categorical
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">tensorflow</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">tf</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.model_selection</span> <span style="color: #008000; font-weight: bold">import</span> train_test_split
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.preprocessing</span> <span style="color: #008000; font-weight: bold">import</span> StandardScaler, OneHotEncoder
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.metrics</span> <span style="color: #008000; font-weight: bold">import</span> confusion_matrix, accuracy_score, roc_auc_score
</pre></div>
<p>
The following runs the data preparation that is used for all models.

<p>
We scale all features by SciKit-learn's standard scaler. The standard
scalars subtracts the mean, so that the means of the standardized
variables equal zero. Furthermore the standard scaler divides the
features by their respective variances, meaning that the variances of the
standardized features equals one.

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #408080; font-style: italic"># Trying to set the seed</span>
np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>seed(<span style="color: #666666">0</span>)
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">random</span>
random<span style="color: #666666">.</span>seed(<span style="color: #666666">0</span>)

<span style="color: #408080; font-style: italic"># Reading file into data frame</span>
cwd <span style="color: #666666">=</span> os<span style="color: #666666">.</span>getcwd()
filename <span style="color: #666666">=</span> cwd <span style="color: #666666">+</span> <span style="color: #BA2121">&#39;/default of credit card clients.xls&#39;</span>
nanDict <span style="color: #666666">=</span> {}
df <span style="color: #666666">=</span> pd<span style="color: #666666">.</span>read_excel(filename, header<span style="color: #666666">=1</span>, skiprows<span style="color: #666666">=0</span>, index_col<span style="color: #666666">=0</span>, na_values<span style="color: #666666">=</span>nanDict)

df<span style="color: #666666">.</span>rename(index<span style="color: #666666">=</span><span style="color: #008000">str</span>, columns<span style="color: #666666">=</span>{<span style="color: #BA2121">&quot;default payment next month&quot;</span>: <span style="color: #BA2121">&quot;defaultPaymentNextMonth&quot;</span>}, inplace<span style="color: #666666">=</span><span style="color: #008000">True</span>)

<span style="color: #408080; font-style: italic"># Features and targets </span>
X <span style="color: #666666">=</span> df<span style="color: #666666">.</span>loc[:, df<span style="color: #666666">.</span>columns <span style="color: #666666">!=</span> <span style="color: #BA2121">&#39;defaultPaymentNextMonth&#39;</span>]<span style="color: #666666">.</span>values
y <span style="color: #666666">=</span> df<span style="color: #666666">.</span>loc[:, df<span style="color: #666666">.</span>columns <span style="color: #666666">==</span> <span style="color: #BA2121">&#39;defaultPaymentNextMonth&#39;</span>]<span style="color: #666666">.</span>values

<span style="color: #408080; font-style: italic"># Categorical variables to one-hot&#39;s</span>
onehotencoder <span style="color: #666666">=</span> OneHotEncoder(categorical_features <span style="color: #666666">=</span> [<span style="color: #666666">3</span>])
X <span style="color: #666666">=</span> onehotencoder<span style="color: #666666">.</span>fit_transform(X)<span style="color: #666666">.</span>toarray()
X <span style="color: #666666">=</span> X[:, <span style="color: #666666">1</span>:] 

<span style="color: #408080; font-style: italic"># Train-test split</span>
trainingShare <span style="color: #666666">=</span> <span style="color: #666666">0.5</span> 
seed  <span style="color: #666666">=</span> <span style="color: #666666">1</span>
XTrain, XTest, yTrain, yTest<span style="color: #666666">=</span>train_test_split(X, y, train_size<span style="color: #666666">=</span>trainingShare, \
                                              test_size <span style="color: #666666">=</span> <span style="color: #666666">1-</span>trainingShare,
                                             random_state<span style="color: #666666">=</span>seed)

<span style="color: #408080; font-style: italic"># Input Scaling</span>
sc <span style="color: #666666">=</span> StandardScaler()
XTrain <span style="color: #666666">=</span> sc<span style="color: #666666">.</span>fit_transform(XTrain)
XTest <span style="color: #666666">=</span> sc<span style="color: #666666">.</span>transform(XTest)

<span style="color: #408080; font-style: italic"># One-hot&#39;s of the target vector</span>
Y_train_onehot, Y_test_onehot <span style="color: #666666">=</span> to_categorical(yTrain), to_categorical(yTest)

<span style="color: #408080; font-style: italic"># Remove instances with zeros only for past bill statements or paid amounts</span>

df <span style="color: #666666">=</span> df<span style="color: #666666">.</span>drop(df[(df<span style="color: #666666">.</span>BILL_AMT1 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>BILL_AMT2 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>BILL_AMT3 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>BILL_AMT4 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>BILL_AMT5 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>BILL_AMT6 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>PAY_AMT1 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>PAY_AMT2 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>PAY_AMT3 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>PAY_AMT4 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>PAY_AMT5 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>PAY_AMT6 <span style="color: #666666">==</span> <span style="color: #666666">0</span>)]<span style="color: #666666">.</span>index)

df <span style="color: #666666">=</span> df<span style="color: #666666">.</span>drop(df[(df<span style="color: #666666">.</span>BILL_AMT1 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>BILL_AMT2 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>BILL_AMT3 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>BILL_AMT4 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>BILL_AMT5 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>BILL_AMT6 <span style="color: #666666">==</span> <span style="color: #666666">0</span>)]<span style="color: #666666">.</span>index)

df <span style="color: #666666">=</span> df<span style="color: #666666">.</span>drop(df[(df<span style="color: #666666">.</span>PAY_AMT1 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>PAY_AMT2 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>PAY_AMT3 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>PAY_AMT4 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>PAY_AMT5 <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">&amp;</span>
                (df<span style="color: #666666">.</span>PAY_AMT6 <span style="color: #666666">==</span> <span style="color: #666666">0</span>)]<span style="color: #666666">.</span>index)

<span style="color: #408080; font-style: italic"># Descriptive information</span>
<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&#39;Number of empty elements in data: &#39;</span>, df<span style="color: #666666">.</span>isnull()<span style="color: #666666">.</span>values<span style="color: #666666">.</span>any())
<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&#39;Observations: &#39;</span>, df<span style="color: #666666">.</span>shape[<span style="color: #666666">0</span>])
<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&#39;Percentage defaults: &#39;</span>, df[<span style="color: #BA2121">&#39;defaultPaymentNextMonth&#39;</span>]<span style="color: #666666">.</span>astype(<span style="color: #008000">bool</span>)<span style="color: #666666">.</span>sum(axis<span style="color: #666666">=0</span>)<span style="color: #666666">/</span>df<span style="color: #666666">.</span>shape[<span style="color: #666666">0</span>]<span style="color: #666666">*100</span>)
</pre></div>
<p>
This is not the same number of observations as in Yeh and Lien
(2009). Yeh and Lien (2009) have 25 000 observations. However, we have
the same number of observations as in Pyzhov and Pyzhov (2017), which
is said to use the same dataset as Yeh and Lien (2009).

<p>
The percentage of individuals with default is the same as in the Yeh and Lien (2009).

<p>
Will will essentially deal with two classes.
For two classen and two paramaters we have
$$
\begin{align*}
p(y_i=1|x_i,\hat{\beta}) &= \frac{\exp{(\beta_0+\beta_1x_i)}}{1+\exp{(\beta_0+\beta_1x_i)}},\nonumber\\
p(y_i=0|x_i,\hat{\beta}) &= 1 - p(y_i=1|x_i,\hat{\beta}),
\end{align*}
$$

The solution is found by maximizing the likelihhod function
$$
\begin{align*}
P(\mathcal{D}|\hat{\beta})& = \prod_{i=1}^n \left[p(y_i=1|x_i,\hat{\beta})\right]^{y_i}\left[1-p(y_i=1|x_i,\hat{\beta}))\right]^{1-y_i}\nonumber \\
\end{align*}
$$

We will use the cross-entropy as objective function. The cross-entropy is the negative log of the likelihood function

$$
\mathcal{C}(\hat{\beta})=-\sum_{i=1}^n  \left(y_i(\beta_0+\beta_1x_i) -\log{(1+\exp{(\beta_0+\beta_1x_i)})}\right).
$$

The minus sign in the cross-entropy is in order to make this a convex function so that we get a minimization problem.

<p>
To find the minimum of the above function, we differentiate it and set the result to zero

$$
\frac{\partial \mathcal{C}(\hat{\beta})}{\partial \beta_0} = -\sum_{i=1}^n  \left(y_i -\frac{\exp{(\beta_0+\beta_1x_i)}}{1+\exp{(\beta_0+\beta_1x_i)}}\right),
$$


$$
\frac{\partial \mathcal{C}(\hat{\beta})}{\partial \beta_1} = -\sum_{i=1}^n  \left(y_ix_i -x_i\frac{\exp{(\beta_0+\beta_1x_i)}}{1+\exp{(\beta_0+\beta_1x_i)}}\right). 
$$

<p>
The above can be rewritten as
$$
\frac{\partial \mathcal{C}(\hat{\beta})}{\partial \hat{\beta}} = -\hat{X}^T\left(\hat{y}-\hat{p}\right).
$$

<p>
We see that there is no explicit expression for the parameters, like
we have in e.g. OLS. Hence iterative methods must be applied, and we
will apply the gradient descent method which basically says for some
variabe \( \theta \), we update it with

$$
\hat{\theta} = \hat{\theta} - \eta \nabla \hat{\theta}.
$$

<p>
The second term in the above equation is the gradient. In our case the
gradient for the regression parameters are given by the linear algebra
equation above

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.linear_model</span> <span style="color: #008000; font-weight: bold">import</span> LogisticRegression
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.model_selection</span> <span style="color: #008000; font-weight: bold">import</span> GridSearchCV

lmbdas<span style="color: #666666">=</span>np<span style="color: #666666">.</span>logspace(<span style="color: #666666">-5</span>,<span style="color: #666666">7</span>,<span style="color: #666666">13</span>)
parameters <span style="color: #666666">=</span> [{<span style="color: #BA2121">&#39;C&#39;</span>: <span style="color: #666666">1./</span>lmbdas}]
scoring <span style="color: #666666">=</span> [<span style="color: #BA2121">&#39;accuracy&#39;</span>, <span style="color: #BA2121">&#39;roc_auc&#39;</span>]
logReg <span style="color: #666666">=</span> LogisticRegression()
gridSearch <span style="color: #666666">=</span> GridSearchCV(logReg, parameters, cv<span style="color: #666666">=5</span>, scoring<span style="color: #666666">=</span>scoring, refit<span style="color: #666666">=</span><span style="color: #BA2121">&#39;roc_auc&#39;</span>) 
<span style="color: #408080; font-style: italic"># &quot;refit&quot; gives the metric used deciding best model. </span>
<span style="color: #408080; font-style: italic"># See more http://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html</span>
gridSearch<span style="color: #666666">.</span>fit(XTrain, yTrain<span style="color: #666666">.</span>ravel())
</pre></div>
<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">gridSearchSummary</span>(method, scoring):
    <span style="color: #BA2121; font-style: italic">&quot;&quot;&quot;Prints best parameters from Grid search</span>
<span style="color: #BA2121; font-style: italic">    and AUC with standard deviation for all </span>
<span style="color: #BA2121; font-style: italic">    parameter combos &quot;&quot;&quot;</span>
    
    method <span style="color: #666666">=</span> <span style="color: #008000">eval</span>(method)
    <span style="color: #008000; font-weight: bold">if</span> scoring <span style="color: #666666">==</span> <span style="color: #BA2121">&#39;accuracy&#39;</span>:
        mean <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;mean_test_score&#39;</span>
        sd <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;std_test_score&#39;</span>
    <span style="color: #008000; font-weight: bold">elif</span> scoring <span style="color: #666666">==</span> <span style="color: #BA2121">&#39;auc&#39;</span>:
        mean <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;mean_test_roc_auc&#39;</span>
        sd <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;std_test_roc_auc&#39;</span>
    <span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&quot;Best: </span><span style="color: #BB6688; font-weight: bold">%f</span><span style="color: #BA2121"> using </span><span style="color: #BB6688; font-weight: bold">%s</span><span style="color: #BA2121">&quot;</span> <span style="color: #666666">%</span> (method<span style="color: #666666">.</span>best_score_, method<span style="color: #666666">.</span>best_params_))
    means <span style="color: #666666">=</span> method<span style="color: #666666">.</span>cv_results_[mean]
    stds <span style="color: #666666">=</span> method<span style="color: #666666">.</span>cv_results_[sd]
    params <span style="color: #666666">=</span> method<span style="color: #666666">.</span>cv_results_[<span style="color: #BA2121">&#39;params&#39;</span>]
    <span style="color: #008000; font-weight: bold">for</span> mean, stdev, param <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">zip</span>(means, stds, params):
        <span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&quot;</span><span style="color: #BB6688; font-weight: bold">%f</span><span style="color: #BA2121"> (</span><span style="color: #BB6688; font-weight: bold">%f</span><span style="color: #BA2121">) with: </span><span style="color: #BB6688; font-weight: bold">%r</span><span style="color: #BA2121">&quot;</span> <span style="color: #666666">%</span> (mean, stdev, param))

gridSearchSummary(<span style="color: #BA2121">&#39;gridSearch&#39;</span>, <span style="color: #BA2121">&#39;auc&#39;</span>)
</pre></div>
<p>
We create a function for printing the accuracy of the results and the so-called confusion matrices.
<p>

<!-- code=text typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>def createConfusionMatrix(method, printOut=True):
    &quot;&quot;&quot;
    Computes and prints confusion matrices, accuracy scores,
    and AUC for test and training sets 
    &quot;&quot;&quot;
    confusionArray = np.zeros(6, dtype=object)
    method = eval(method)
    
    # Train
    yPredTrain = method.predict(XTrain)
    yPredTrain = (yPredTrain &gt; 0.5)
    cm = confusion_matrix(
        yTrain, yPredTrain) 
    cm = np.around(cm/cm.sum(axis=1)[:,None], 2)
    confusionArray[0] = cm
    
    accScore = accuracy_score(yTrain, yPredTrain)
    confusionArray[1] = accScore
    
    AUC = roc_auc_score(yTrain, yPredTrain)
    confusionArray[2] = AUC
    
    if printOut:
        print(&#39;\n###################  Training  ###############&#39;)
        print(&#39;\nTraining Confusion matrix: \n&#39;, cm)
        print(&#39;\nTraining Accuracy score: \n&#39;, accScore)
        print(&#39;\nTrain AUC: \n&#39;, AUC)
    
    # Test
    yPred = method.predict(XTest)
    yPred = (yPred &gt; 0.5)
    cm = confusion_matrix(
        yTest, yPred) 
    cm = np.around(cm/cm.sum(axis=1)[:,None], 2)
    confusionArray[3] = cm
    
    accScore = accuracy_score(yTest, yPred)
    confusionArray[4] = accScore
    
    AUC = roc_auc_score(yTest, yPred)
    confusionArray[5] = AUC
    
    if printOut:
        print(&#39;\n###################  Testing  ###############&#39;)
        print(&#39;\nTest Confusion matrix: \n&#39;, cm)
        print(&#39;\nTest Accuracy score: \n&#39;, accScore)
        print(&#39;\nTestAUC: \n&#39;, AUC)    
    
    return confusionArray


confusionArrayLogreg = createConfusionMatrix(&#39;gridSearch&#39;, printOut=False)
</pre></div>
<p>

<!-- code=text typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>import matplotlib.pyplot as plt
import seaborn
import scikitplot as skplt

seaborn.set(style=&quot;white&quot;, context=&quot;notebook&quot;, font_scale=1.5, 
            rc={&quot;axes.grid&quot;: True, &quot;legend.frameon&quot;: False,
&quot;lines.markeredgewidth&quot;: 1.4, &quot;lines.markersize&quot;: 10})
seaborn.set_context(&quot;notebook&quot;, font_scale=1.5, rc={&quot;lines.linewidth&quot;: 4.5})

yPred = gridSearch.predict_proba(XTest) 
print(yTest.ravel().shape, yPred.shape)
skplt.metrics.plot_cumulative_gain(yTest.ravel(), yPred)

defaults = sum(yTest == 1)
total = len(yTest)
defaultRate = defaults/total
def bestCurve(defaults, total, defaultRate):
    x = np.linspace(0, 1, total)
    
    y1 = np.linspace(0, 1, defaults)
    y2 = np.ones(total-defaults)
    y3 = np.concatenate([y1,y2])
    return x, y3

x, best = bestCurve(defaults=defaults, total=total, defaultRate=defaultRate)    
plt.plot(x, best)    

plt.show()
</pre></div>
<p>
<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._LogReg-bs022.html">&laquo;</a></li>
  <li><a href="._LogReg-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._LogReg-bs015.html">16</a></li>
  <li><a href="._LogReg-bs016.html">17</a></li>
  <li><a href="._LogReg-bs017.html">18</a></li>
  <li><a href="._LogReg-bs018.html">19</a></li>
  <li><a href="._LogReg-bs019.html">20</a></li>
  <li><a href="._LogReg-bs020.html">21</a></li>
  <li><a href="._LogReg-bs021.html">22</a></li>
  <li><a href="._LogReg-bs022.html">23</a></li>
  <li class="active"><a href="._LogReg-bs023.html">24</a></li>
  <li><a href="._LogReg-bs024.html">25</a></li>
  <li><a href="._LogReg-bs024.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="http://..."><img width="250" align=right src="http://..."></a>
</footer>
-->


<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>


</body>
</html>
    


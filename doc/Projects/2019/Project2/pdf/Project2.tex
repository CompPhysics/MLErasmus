%%
%% Automatically generated file from DocOnce source
%% (https://github.com/hplgit/doconce/)
%%
%%


%-------------------- begin preamble ----------------------

\documentclass[%
oneside,                 % oneside: electronic viewing, twoside: printing
final,                   % draft: marks overfull hboxes, figures with paths
10pt]{article}

\listfiles               %  print all files needed to compile this document

\usepackage{relsize,makeidx,color,setspace,amsmath,amsfonts,amssymb}
\usepackage[table]{xcolor}
\usepackage{bm,ltablex,microtype}

\usepackage[pdftex]{graphicx}

\usepackage[T1]{fontenc}
%\usepackage[latin1]{inputenc}
\usepackage{ucs}
\usepackage[utf8x]{inputenc}

\usepackage{lmodern}         % Latin Modern fonts derived from Computer Modern

% Hyperlinks in PDF:
\definecolor{linkcolor}{rgb}{0,0,0.4}
\usepackage{hyperref}
\hypersetup{
    breaklinks=true,
    colorlinks=true,
    linkcolor=linkcolor,
    urlcolor=linkcolor,
    citecolor=black,
    filecolor=black,
    %filecolor=blue,
    pdfmenubar=true,
    pdftoolbar=true,
    bookmarksdepth=3   % Uncomment (and tweak) for PDF bookmarks with more levels than the TOC
    }
%\hyperbaseurl{}   % hyperlinks are relative to this root

\setcounter{tocdepth}{2}  % levels in table of contents

% prevent orhpans and widows
\clubpenalty = 10000
\widowpenalty = 10000

% --- end of standard preamble for documents ---


% insert custom LaTeX commands...

\raggedbottom
\makeindex
\usepackage[totoc]{idxlayout}   % for index in the toc
\usepackage[nottoc]{tocbibind}  % for references/bibliography in the toc

%-------------------- end preamble ----------------------

\begin{document}

% matching end for #ifdef PREAMBLE

\newcommand{\exercisesection}[1]{\subsection*{#1}}


% ------------------- main content ----------------------



% ----------------- title -------------------------

\thispagestyle{empty}

\begin{center}
{\LARGE\bf
\begin{spacing}{1.25}
Project 2 on Machine Learning, deadline February 20, 2020
\end{spacing}
}
\end{center}

% ----------------- author(s) -------------------------

\begin{center}
{\bf Data Analysis and Machine Learning${}^{}$} \\ [0mm]
\end{center}

\begin{center}
% List of all institutions:
\end{center}
    
% ----------------- end author(s) -------------------------

% --- begin date ---
\begin{center}
Jan 30, 2020
\end{center}
% --- end date ---

\vspace{1cm}


\subsection*{Paths for project 2}

For project 2, you can propose own data sets that relate to your
research interests or just use existing data sets from say

\begin{enumerate}
\item \href{{https://www.kaggle.com/datasets}}{Kaggle}

\item \href{{https://archive.ics.uci.edu/ml/index.php}}{The University of California at Irvine (UCI) with its machine learning repository}

\item The credit card data set from \href{{https://archive.ics.uci.edu/ml/index.php}}{UCI} is also interesting and links to a recent scientific article. See however below for possible project example

\item \href{{https://www.kaggle.com/pavanraj159/predicting-pulsar-star-in-the-universe/notebook?scriptVersionId=4487650}}{The pulsar classification data set is obtained from Kaggle}, where it was posted by Pavan Raj. The data file is available in the DataFiles folder of this project.

\item Or other data sets you find interesting and relevant.
\end{enumerate}

\noindent
The approach to the analysis of these new data sets should follow to a
large extent what you did in project 1. That is: Whether you end up
with a regression or a classification problem, you should employ at
least two of the methods we have discussed among linear regression
(including Ridge and Lasso), Logistic Regression, Neural Networks,
Support Vector Machines (not covered during the lectures) and Decision Trees, Random Forests, Bagging and Boosting. If you
wish to venture into convolutional neural networks or recurrent neural
networks, or extensions of neural networks, feel free to do so.  For
project 2, you should feel free to write your own code or use the
available functionality of scikit-learn, tensorflow, etc.

The estimates you used and tested in project 1 should also be
included, that is the R2-score, MSE, cross-validation and/or bootstrap
if these are relevant.  If possible, you should link the data sets
with exisiting research and analyses thereof. Scientific articles
which have used Machine Learning algorithms to analyze the data are
highly welcome. Perhaps you can improve previous analyses and even
publish a new article?  A critical assessment of the methods with
ditto perspectives and recommendations is also something you need to
include.  All in all, the report should follow the same pattern with
abstract, introduction, methods, code, results, conclusions etc as in project 1.

\paragraph{Studying the credit card data set as possible project.}
We include this data set as an example on how one could study new data
sets with the algorithms we have discussed during the lectures, using
either your own codes or the functionality of scikit-learn, tensorflow
or other Python packages.

The data set is presented at the site of \href{{https://archive.ics.uci.edu/ml/index.php}}{UCI}. It is particularly
interesting since it is also analyzed using ML methods in a recent
scientific article.

The authors apply several ML methods, from nearest neighbors via
logistic regression to neural networks and Bayesian analysis (not
covered much in our course). Here follows a set up on how to analyze
these data.

\paragraph{Part a).}
The first part deals with structuring and reading the data, much along the same lines as done in projects 1 and 2.

\paragraph{Part b).}
Perform a logistic regression analysis and see if you can reproduce the results of figure 3 of the above article.

\paragraph{Part c).}
The next step is to use neural networks and the functionality provided
by tensorflow/keras or scikit-learn's MLP method (or you could write
your own code). Compare and discuss again your results with those from
the above article.

\paragraph{Part d).}
The above article does not study random forests or support vector
machine algorithms. Try to apply one of these methods or both to the
credit card data and see if these methods provide a better description
of the data. Can you outperform the authors of the article?

\paragraph{Part e).}
Finally, here you should present a critical assessment of the methods
you have studied and link your results with the existing literature.


\paragraph{The Pulsar data.}
The pulsar classification data set is obtained from
Kaggle, where it was posted by Pavan Raj. It offers an interesting
possible classification problem. In the field of radio astronomy,
pulsars are among the most studied phenomena in nature. But despite
astronomers' long history with pulsars, little is actually known with
certainty. However, much of the uncertainty likely boils down to the
difficulty of confirming pulsar observations. While pulsars radiate
unmistakable radio signals, they are often lost in the sheer number of
radio signals observed by radio telescopes every day. Furthermore, due
to the uniqueness of pulsar radio signals, classifying pulsars in
large data sets of radio observations have historically been very
difficult as human supervision has been a necessity. However, recent
advances in machine learning and data mining has made this task
much simpler by introducing incredibly fast, in comparison to humans
that is, classification methods.

You could repeat many of the steps discussed for the credit card data problem. The article of \href{{https://arxiv.org/abs/1209.0793}}{Bathes et. al.} can serve as a reference for your discussions.


% ------------------- end of main content ---------------

\end{document}


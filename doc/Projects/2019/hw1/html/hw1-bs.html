<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Homework 1">

<title>Homework 1</title>

<!-- Bootstrap style: bootstrap -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}

/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Exercise 1', 2, None, '___sec0'),
              ('Exercise 2', 2, None, '___sec1'),
              ('Simple Random walk', 3, None, '___sec2'),
              ('Simple Linear algebra example', 3, None, '___sec3'),
              ('Exercise 3', 2, None, '___sec4'),
              ('Exercise 4, variance of the parameters $\\beta$ in linear '
               'regression',
               2,
               None,
               '___sec5'),
              ('Solution to exercise 3', 2, None, '___sec6')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="hw1-bs.html">Homework 1</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="#___sec0" style="font-size: 80%;"><b>Exercise 1</b></a></li>
     <!-- navigation toc: --> <li><a href="#___sec1" style="font-size: 80%;"><b>Exercise 2</b></a></li>
     <!-- navigation toc: --> <li><a href="#___sec2" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Simple Random walk</a></li>
     <!-- navigation toc: --> <li><a href="#___sec3" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Simple Linear algebra example</a></li>
     <!-- navigation toc: --> <li><a href="#___sec4" style="font-size: 80%;"><b>Exercise 3</b></a></li>
     <!-- navigation toc: --> <li><a href="#___sec5" style="font-size: 80%;"><b>Exercise 4, variance of the parameters \( \beta \) in linear regression</b></a></li>
     <!-- navigation toc: --> <li><a href="#___sec6" style="font-size: 80%;"><b>Solution to exercise 3</b></a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0000"></a>
<!-- ------------------- main content ---------------------- -->



<div class="jumbotron">
<center><h1>Homework 1</h1></center>  <!-- document title -->

<p>
<!-- author(s): Data Analysis and Machine Learning -->

<center>
<b>Data Analysis and Machine Learning</b> 
</center>

<p>
<!-- institution(s) -->

<br>
<p>
<center><h4>Jan 22, 2019</h4></center> <!-- date -->
<br>
<p>
</div> <!-- end jumbotron -->

<h2 id="___sec0" class="anchor">Exercise 1  </h2>

<p>
The first exercise here is of a mere technical art. We want you to have 

<ul>
<li> git as a version control software and to establish a user account on a provider like GitHub. Other providers like GitLab etc are equally fine. You can also use the University of Oslo <a href="https://www.uio.no/tjenester/it/maskin/filer/versjonskontroll/github.html" target="_self">GitHub facilities</a>.</li> 
<li> Install various Python packages</li>
</ul>

We will make extensive use of Python as programming language and its
myriad of available libraries.  You will find
IPython/Jupyter notebooks invaluable in your work.  You can run <b>R</b>
codes in the Jupyter/IPython notebooks, with the immediate benefit of
visualizing your data. You can also use compiled languages like C++,
Rust, Fortran etc if you prefer. The focus in these lectures will be
on Python.

<p>
If you have Python installed (we recommend Python3.6 or higher versions) and you feel
pretty familiar with installing different packages, we recommend that
you install the following Python packages via <b>pip</b> as 

<ol>
<li> pip install numpy scipy matplotlib ipython scikit-learn sympy pandas pillow</li> 
</ol>

For <b>Tensorflow</b>, we recommend following the instructions in the text of 
<a href="http://shop.oreilly.com/product/0636920052289.do" target="_self">Aurelien Geron, Hands&#8209;On Machine Learning with Scikit&#8209;Learn and TensorFlow, O'Reilly</a>

<p>
We will come back to <b>tensorflow</b> later.

<p>
For Python3, replace <b>pip</b> with <b>pip3</b>.

<p>
For OSX users we recommend, after having installed Xcode, to
install <b>brew</b>. Brew allows for a seamless installation of additional
software via for example 

<ol>
<li> brew install python3</li>
</ol>

For Linux users, with its variety of distributions like for example the widely popular Ubuntu distribution,
you can use <b>pip</b> as well and simply install Python as 

<ol>
<li> sudo apt-get install python3  (or python for pyhton2.7)</li>
</ol>

If you don't want to perform these operations separately and venture
into the hassle of exploring how to set up dependencies and paths, we
recommend two widely used distrubutions which set up all relevant
dependencies for Python, namely 

<ul>
<li> <a href="https://docs.anaconda.com/" target="_self">Anaconda</a>,</li> 
</ul>

which is an open source
distribution of the Python and R programming languages for large-scale
data processing, predictive analytics, and scientific computing, that
aims to simplify package management and deployment. Package versions
are managed by the package management system <b>conda</b>. 

<ul>
<li> <a href="https://www.enthought.com/product/canopy/" target="_self">Enthought canopy</a></li> 
</ul>

is a Python
distribution for scientific and analytic computing distribution and
analysis environment, available for free and under a commercial
license.

<p>
We recommend using <b>Anaconda</b>.

<h2 id="___sec1" class="anchor">Exercise 2 </h2>

<p>
You should install and explore

<ol>
<li> Numpy and Scipy</li>
<li> Matplotlib</li>
<li> Pandas</li>
<li> Jupyter notebook</li>
</ol>

<h3 id="___sec2" class="anchor">Simple Random walk </h3>

Make then a simple program which simulates a random walk and then plots the first 100 values. The example here may help.
<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">random</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
position <span style="color: #666666">=</span> <span style="color: #666666">0</span>  
steps <span style="color: #666666">=</span> <span style="color: #666666">1000</span>
walk <span style="color: #666666">=</span> []
<span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(steps):     
    step <span style="color: #666666">=</span> <span style="color: #666666">1</span> <span style="color: #008000; font-weight: bold">if</span> random<span style="color: #666666">.</span>randint(<span style="color: #666666">0</span>,<span style="color: #666666">1</span>) <span style="color: #008000; font-weight: bold">else</span> <span style="color: #666666">-1</span>
    position<span style="color: #666666">+=</span> step
    walk<span style="color: #666666">.</span>append(position)

plt<span style="color: #666666">.</span>plot(walk[:<span style="color: #666666">100</span>])
plt<span style="color: #666666">.</span>show()
</pre></div>

<h3 id="___sec3" class="anchor">Simple Linear algebra example </h3>

Write a simple program which performs basic matrix-vector multiplications and finds also the inverse of a matrix. You could use the following example
<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">numpy.linalg</span> <span style="color: #008000; font-weight: bold">import</span> inv
x <span style="color: #666666">=</span> np<span style="color: #666666">.</span>array([[<span style="color: #666666">1.</span>, <span style="color: #666666">2.</span>, <span style="color: #666666">3.</span>],[<span style="color: #666666">4.</span>,<span style="color: #666666">5.</span>,<span style="color: #666666">6.</span>]])
y <span style="color: #666666">=</span> np<span style="color: #666666">.</span>array([[<span style="color: #666666">6.</span>,<span style="color: #666666">23</span>,],[<span style="color: #666666">-1.</span>,<span style="color: #666666">7.</span>],[<span style="color: #666666">8.</span>,<span style="color: #666666">9.</span>]])
<span style="color: #008000; font-weight: bold">print</span>(x)
<span style="color: #008000; font-weight: bold">print</span>(y)
z <span style="color: #666666">=</span> x<span style="color: #666666">.</span>dot(y)
<span style="color: #408080; font-style: italic"># equivalent to np.dot(x,y)</span>
<span style="color: #008000; font-weight: bold">print</span>(z)
<span style="color: #008000; font-weight: bold">print</span>(np<span style="color: #666666">.</span>dot(x,y))
z <span style="color: #666666">=</span> np<span style="color: #666666">.</span>dot(x,np<span style="color: #666666">.</span>ones(<span style="color: #666666">3</span>))
<span style="color: #408080; font-style: italic"># or write it as </span>
z <span style="color: #666666">=</span> x @ np<span style="color: #666666">.</span>ones(<span style="color: #666666">3</span>)
<span style="color: #008000; font-weight: bold">print</span>(z)

X <span style="color: #666666">=</span> np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>randn(<span style="color: #666666">5</span>,<span style="color: #666666">5</span>)
mat <span style="color: #666666">=</span> X<span style="color: #666666">.</span>T<span style="color: #666666">.</span>dot(X)
<span style="color: #008000; font-weight: bold">print</span>(inv(mat))
<span style="color: #008000; font-weight: bold">print</span>(mat<span style="color: #666666">.</span>dot(inv(mat)))
</pre></div>

<h2 id="___sec4" class="anchor">Exercise 3  </h2>

<p>
We will generate our own dataset for a function \( y(x) \) where \( x \in [0,1] \) and defined by random numbers computed with the uniform distribution. The function \( y \) is a quadratic polynomial in \( x \) with added stochastic noise according to the normal distribution \( \cal {N}(0,1) \).
The following simple Python instructions define our \( x \) and \( y \) values (with 100 data points).
<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>x <span style="color: #666666">=</span> np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>rand(<span style="color: #666666">100</span>,<span style="color: #666666">1</span>)
y <span style="color: #666666">=</span> <span style="color: #666666">5*</span>x<span style="color: #666666">*</span>x<span style="color: #666666">+0.1*</span>np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>randn(<span style="color: #666666">100</span>,<span style="color: #666666">1</span>)
</pre></div>
<ol>
<li> Write your own code (following the examples under the <a href="https://compphysics.github.io/MachineLearning/doc/pub/Regression/html/Regression-bs.html" target="_self">regression slides</a>) for computing the parametrization of the data set fitting a second-order polynomial.</li> 
<li> Use thereafter <b>scikit-learn</b> (see again the examples in the regression slides) and compare with your own code.</li>   
<li> Using scikit-learn, compute also the mean square error, a risk metric corresponding to the expected value of the squared (quadratic) error defined as</li>
</ol>

$$ MSE(\hat{y},\hat{\tilde{y}}) = \frac{1}{n}
\sum_{i=0}^{n-1}(y_i-\tilde{y}_i)^2, 
$$

and the \( R^2 \) score function.
If \( \tilde{\hat{y}}_i \) is the predicted value of the \( i-th \) sample and \( y_i \) is the corresponding true value, then the score \( R^2 \) is defined as
$$
R^2(\hat{y}, \tilde{\hat{y}}) = 1 - \frac{\sum_{i=0}^{n - 1} (y_i - \tilde{y}_i)^2}{\sum_{i=0}^{n - 1} (y_i - \bar{y})^2},
$$

where we have defined the mean value  of \( \hat{y} \) as
$$
\bar{y} =  \frac{1}{n} \sum_{i=0}^{n - 1} y_i.
$$

You can use the functionality included in scikit-learn. If you feel for it, you can use your own program and define functions which compute the above two functions. 
Discuss the meaning of these results. Try also to vary the coefficient in front of the added stochastic noise term and discuss the quality of the fits.

<h2 id="___sec5" class="anchor">Exercise 4, variance of the parameters \( \beta \) in linear regression  </h2>

<p>
Show that the variance of the parameters \( \beta \) in the linear regression method (chapter 3, equation (3.8) of <a href="https://www.springer.com/gp/book/9780387848570" target="_self">Trevor Hastie, Robert Tibshirani, Jerome H. Friedman, The Elements of Statistical Learning, Springer</a>) is given as 

$$
\mathrm{Var}(\hat{\beta}) = \left(\hat{X}^T\hat{X}\right)^{-1}\sigma^2,
$$

with 
$$
\sigma^2 = \frac{1}{N-p-1}\sum_{i=1}^{N} (y_i-\tilde{y}_i)^2,
$$

where we have assumed that we fit a function of degree \( p-1 \) (for example a polynomial in \( x \)).

<h2 id="___sec6" class="anchor">Solution to exercise 3 </h2>

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>

n <span style="color: #666666">=</span> <span style="color: #666666">100</span> <span style="color: #408080; font-style: italic"># data points</span>
xmax <span style="color: #666666">=</span> <span style="color: #666666">1</span>
error <span style="color: #666666">=</span> <span style="color: #666666">0.1</span>

<span style="color: #408080; font-style: italic"># The following simple Python instructions define our x and y values (with 100 data points)</span>
x <span style="color: #666666">=</span> np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>rand(n,xmax)
y <span style="color: #666666">=</span> <span style="color: #666666">5*</span>x<span style="color: #666666">*</span>x<span style="color: #666666">+</span>error<span style="color: #666666">*</span>np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>randn(n,xmax) <span style="color: #408080; font-style: italic"># y = 5x^2 + noise</span>

<span style="color: #408080; font-style: italic">#for xi, yi in zip(x, y):</span>
<span style="color: #408080; font-style: italic">#    print(xi, yi)</span>
</pre></div>
<p>
The above defines a set of equations

<p>
\( \hat{y} = \hat{X}\hat{\beta} + \hat{\epsilon} \)

<p>
where the elements of \( \hat{y} \) are given by \( y_i = 5x_i + \epsilon_i \). Afterwards, \( \hat{y} \) is turned into a \( 100\times1 \) matrix so that <code>np.linalg</code> can accept it as input.

<p>
We define the matrix 
$$
\hat{X}=\begin{bmatrix} 
1 & x_0 & x_0^2 \\
1 & x_1 & x_1^2 \\
\vdots & \vdots & \vdots \\
1 & x_{99} & x_{99}^2
\end{bmatrix}
$$

with \( x_0 \), \( x_1 \), \( \dots x_{99} \) given by <code>x = np.random.rand(100,1)</code>. \( \hat{X} \) is then given by:

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>X <span style="color: #666666">=</span> np<span style="color: #666666">.</span>c_[np<span style="color: #666666">.</span>ones((n,<span style="color: #666666">1</span>)), x, x<span style="color: #666666">*</span>x] <span style="color: #408080; font-style: italic"># column wise array concatenation</span>
<span style="color: #008000; font-weight: bold">print</span>(X)
</pre></div>
<p>
For an explanation of <code>np.c_</code> see <a href="https://stackoverflow.com/questions/39136730/confused-about-numpy-c-document-and-sample-code" target="_self"><tt>https://stackoverflow.com/questions/39136730/confused-about-numpy-c-document-and-sample-code</tt></a>.

<p>
The solution for the parameters \( \hat{\beta} \) is given by

<p>
\( \hat{\beta} = \left(\hat{X}^T\hat{X}\right)^{-1}\hat{X}^T\hat{y} \)

<p>
or

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>beta <span style="color: #666666">=</span> np<span style="color: #666666">.</span>linalg<span style="color: #666666">.</span>inv(X<span style="color: #666666">.</span>T<span style="color: #666666">.</span>dot(X))<span style="color: #666666">.</span>dot(X<span style="color: #666666">.</span>T)<span style="color: #666666">.</span>dot(y)
<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&quot;y = &quot;</span> <span style="color: #666666">+</span> <span style="color: #008000">str</span>(beta[<span style="color: #666666">2</span>,<span style="color: #666666">0</span>]) <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;*x^2 + &quot;</span> <span style="color: #666666">+</span> <span style="color: #008000">str</span>(beta[<span style="color: #666666">1</span>,<span style="color: #666666">0</span>]) <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;*x + &quot;</span> <span style="color: #666666">+</span> <span style="color: #008000">str</span>(beta[<span style="color: #666666">0</span>,<span style="color: #666666">0</span>]))
</pre></div>
<p>
Now we plot the resulting function over the data points to visualise how good the fit looks (two points would be enough for a line, but it won't cut it for a quadratic fit):

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>nfit <span style="color: #666666">=</span> <span style="color: #666666">100</span>
xplot <span style="color: #666666">=</span> np<span style="color: #666666">.</span>arange(nfit)<span style="color: #666666">*</span>xmax <span style="color: #666666">/</span> (nfit <span style="color: #666666">-</span> <span style="color: #666666">1</span>) <span style="color: #408080; font-style: italic"># nfit points, evenly distributed</span>
<span style="color: #408080; font-style: italic">#print(xplot)</span>
<span style="color: #408080; font-style: italic">#print(xplot**2)</span>
</pre></div>
<p>
Then define a new matrix \( \hat{X}_{\mathrm{plot}} \) for the evenly distributed values we want to use for plotting:

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>Xplot <span style="color: #666666">=</span> np<span style="color: #666666">.</span>c_[np<span style="color: #666666">.</span>ones((nfit,<span style="color: #666666">1</span>)), xplot, xplot<span style="color: #666666">**2</span>] <span style="color: #408080; font-style: italic"># concatenate columns (as above)</span>
</pre></div>
<p>
Finally, calculate the fitted values \( \hat{y}_{\mathrm{predict}} \) using that matrix and the fitted parameters \( \hat{\beta} \):

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>ypredict <span style="color: #666666">=</span> Xplot<span style="color: #666666">.</span>dot(beta)
</pre></div>
<p>
We can plot and compare with the true quadratic function \( y_{\mathrm{true}} = 5x^2 \):

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>ytrue <span style="color: #666666">=</span> <span style="color: #666666">5*</span>xplot<span style="color: #666666">*</span>xplot

plt<span style="color: #666666">.</span>plot(x, y ,<span style="color: #BA2121">&#39;ro&#39;</span>)
plt<span style="color: #666666">.</span>plot(xplot, ytrue, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;$y_{\mathrm{true}}$&quot;</span>)
plt<span style="color: #666666">.</span>plot(xplot, ypredict, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;$y_{\mathrm{predict}}$&quot;</span>)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">r&#39;$x$&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">r&#39;$y$&#39;</span>)
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">r&#39;Quadratic Regression&#39;</span>)
plt<span style="color: #666666">.</span>legend()
plt<span style="color: #666666">.</span>show()
</pre></div>
<p>
We see that this produces a decent enough fit.

<p>
We use thereafter <b>scikit-learn</b>.

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.linear_model</span> <span style="color: #008000; font-weight: bold">import</span> LinearRegression

clf2 <span style="color: #666666">=</span> LinearRegression()
clf2<span style="color: #666666">.</span>fit(X, y)
ysklearn <span style="color: #666666">=</span> clf2<span style="color: #666666">.</span>predict(Xplot)

<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&quot;ypredict = &quot;</span> <span style="color: #666666">+</span> <span style="color: #008000">str</span>(clf2<span style="color: #666666">.</span>coef_[<span style="color: #666666">0</span>, <span style="color: #666666">2</span>]) <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;*x^2 + &quot;</span> <span style="color: #666666">+</span> <span style="color: #008000">str</span>(clf2<span style="color: #666666">.</span>coef_[<span style="color: #666666">0</span>, <span style="color: #666666">1</span>]) <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;*x + &quot;</span> <span style="color: #666666">+</span> <span style="color: #008000">str</span>(clf2<span style="color: #666666">.</span>coef_[<span style="color: #666666">0</span>, <span style="color: #666666">0</span>]))
<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&quot;ysklearn = &quot;</span> <span style="color: #666666">+</span> <span style="color: #008000">str</span>(beta[<span style="color: #666666">2</span>,<span style="color: #666666">0</span>]) <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;*x^2 + &quot;</span> <span style="color: #666666">+</span> <span style="color: #008000">str</span>(beta[<span style="color: #666666">1</span>,<span style="color: #666666">0</span>]) <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;*x + &quot;</span> <span style="color: #666666">+</span> <span style="color: #008000">str</span>(beta[<span style="color: #666666">0</span>,<span style="color: #666666">0</span>]))
<span style="color: #408080; font-style: italic"># note that the indices are reversed in the scikit-learn approach compared to what we did before:</span>
<span style="color: #408080; font-style: italic"># the shape is (1, n) instead of (n, 1)</span>

plt<span style="color: #666666">.</span>plot(x, y ,<span style="color: #BA2121">&#39;ro&#39;</span>)
plt<span style="color: #666666">.</span>plot(xplot, ytrue, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;$y_{\mathrm{true}}$&quot;</span>)
plt<span style="color: #666666">.</span>plot(xplot, ypredict, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;$y_{\mathrm{predict}}$&quot;</span>)
plt<span style="color: #666666">.</span>plot(xplot, ysklearn, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;$y_{\mathrm{sklearn}}$&quot;</span>)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">r&#39;$x$&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">r&#39;$y$&#39;</span>)
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">r&#39;Quadratic Regression&#39;</span>)
plt<span style="color: #666666">.</span>legend()
plt<span style="color: #666666">.</span>show()
</pre></div>
<p>
Plotting the absolute relative error for the two predictions:

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>err_predict <span style="color: #666666">=</span> <span style="color: #008000">abs</span>(ypredict[:, <span style="color: #666666">0</span>] <span style="color: #666666">-</span> ytrue)<span style="color: #666666">/</span><span style="color: #008000">abs</span>(ytrue) <span style="color: #408080; font-style: italic"># the predicted y&#39;s have shape (n, 1)</span>
err_sklearn <span style="color: #666666">=</span> <span style="color: #008000">abs</span>(ysklearn[:, <span style="color: #666666">0</span>] <span style="color: #666666">-</span> ytrue)<span style="color: #666666">/</span><span style="color: #008000">abs</span>(ytrue)

plt<span style="color: #666666">.</span>plot(xplot, err_predict, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;$\epsilon_{\mathrm{predict}}$&quot;</span>)
plt<span style="color: #666666">.</span>plot(xplot, err_sklearn, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;$\epsilon_{\mathrm{sklearn}}$&quot;</span>)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">r&#39;$x$&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">r&#39;$\epsilon_{\mathrm{rel}}$&#39;</span>)
plt<span style="color: #666666">.</span>axis([<span style="color: #666666">0</span>, xmax, <span style="color: #666666">0</span>, <span style="color: #666666">2</span>])
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">r&#39;Absolute relative error&#39;</span>)
plt<span style="color: #666666">.</span>legend()
plt<span style="color: #666666">.</span>show()
</pre></div>
<p>
It is indeed hard to see any difference between the two approaches:

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>plt<span style="color: #666666">.</span>plot(xplot, <span style="color: #008000">abs</span>(err_predict), label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;$\epsilon_{\mathrm{predict}}$&quot;</span>)
plt<span style="color: #666666">.</span>plot(xplot, <span style="color: #008000">abs</span>(err_sklearn), label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;$\epsilon_{\mathrm{sklearn}}$&quot;</span>)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">r&#39;$x$&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">r&#39;$\epsilon_{\mathrm{rel}}$&#39;</span>)
plt<span style="color: #666666">.</span>axis([<span style="color: #666666">0</span>, xmax, <span style="color: #666666">0</span>, <span style="color: #666666">0.02</span>])
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">r&#39;Absolute relative error&#39;</span>)
plt<span style="color: #666666">.</span>legend()
plt<span style="color: #666666">.</span>show()
</pre></div>
<p>
The mean squared error is the expected value of the quadratic error:

<p>
\( MSE\left(\hat{y}, \hat{\bar{y}}\right) = \frac{1}{n}\sum\limits_{i=1}^{n-1}\left(y_i - \bar{y}_i\right)^2 \)

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.metrics</span> <span style="color: #008000; font-weight: bold">import</span> mean_squared_error

<span style="color: #408080; font-style: italic"># Note that the y values are not sorted, but ypredict and ysklearn are</span>
<span style="color: #408080; font-style: italic"># (we used Xplot to find these, not X)</span>
<span style="color: #408080; font-style: italic"># Thus, done with plotting, let us instead make new predictions based on X</span>

ypredict2 <span style="color: #666666">=</span> X<span style="color: #666666">.</span>dot(beta)
ysklearn2 <span style="color: #666666">=</span> clf2<span style="color: #666666">.</span>predict(X)

<span style="color: #408080; font-style: italic"># Then we find the MSE:</span>

<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&quot;Mean squared error (ypredict):&quot;</span>, mean_squared_error(y, ypredict2))
<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&quot;Mean squared error (ysklearn):&quot;</span>, mean_squared_error(y, ysklearn2))
</pre></div>
<p>
The \( R^2 \) score function is defined as

<p>
\( R^2\left(\hat{y}, \hat{\bar{y}}\right) = 1 - \frac{\sum\limits_{i=0}^{n-1}\left(y_i - \bar{y}_i\right)}{\sum\limits_{i=0}^{n-1}\left(y_i - \bar{y}\right)} \)

<p>
where 

<ul>
<li> \( \bar{y} \) is the mean value of \( \hat{y} \)</li>
<li> \( \bar{y}_i \) is the $i$th predicted value, and</li>
<li> \( y_i \) is the corresponding true value</li>
</ul>

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.metrics</span> <span style="color: #008000; font-weight: bold">import</span> r2_score

<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&quot;R^2 score (ypredict):&quot;</span>, r2_score(y, ypredict2))
<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&quot;R^2 score (ysklearn):&quot;</span>, r2_score(y, ysklearn2))
</pre></div>
<p>

<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
  <li class="active"><a href="._hw1-bs000.html">1</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="http://..."><img width="250" align=right src="http://..."></a>
</footer>
-->


</body>
</html>
    

